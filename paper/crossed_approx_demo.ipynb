{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# if need be, manually add the local project root to PYTHONPATH and move working directories\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project = '/' # change to local project root\n",
    "sys.path.append(project)\n",
    "os.chdir(project)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# dependencies\n",
    "\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pystan as stan\n",
    "\n",
    "import xfx.mvglm.multinomial"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# helper functions\n",
    "\n",
    "def package_rfx_samples(rfx_samples, factor_names, response_names, algo_name, chain_ix, epoch_ix):\n",
    "\n",
    "    dfs = []\n",
    "    for i, (samples_, factor_name) in enumerate(zip(rfx_samples, factor_names)):\n",
    "        for j in range(samples_.shape[1]):\n",
    "            df_ = pd.DataFrame(samples_[:, j].T, index=response_names)\n",
    "            df_.index = df_.index.rename('response')\n",
    "            df_.columns = df_.columns.rename('iter')\n",
    "            df_['algo'] = algo_name\n",
    "            df_['chain'] = chain_ix\n",
    "            df_['epoch'] = epoch_ix\n",
    "            df_['factor'] = factor_name\n",
    "            df_['level'] = j\n",
    "            dfs.append(df_)\n",
    "    df = pd.concat(dfs).reset_index().set_index(['algo', 'chain', 'epoch', 'factor', 'level', 'response'])\n",
    "    return df\n",
    "\n",
    "def est_post_moms(samples):\n",
    "\n",
    "    df = pd.DataFrame(index=samples.index)\n",
    "    df['mean'] = samples.mean(1)\n",
    "    df['log_sd'] = np.log(samples.std(1))\n",
    "    df.columns = df.columns.rename('summary')\n",
    "    return df.stack().rename('value')\n",
    "\n",
    "def summ_err(summ, summ_gt):\n",
    "\n",
    "    err = np.abs(summ - summ_gt)\n",
    "    err_med = err.groupby(level=('algo', 'chain', 'epoch', 'summary')).median()\n",
    "    err_max = err.groupby(level=('algo', 'chain', 'epoch', 'summary')).max()\n",
    "    df = pd.DataFrame({'med': err_med, 'max': err_max})\n",
    "    df.columns = df.columns.rename('quantile')\n",
    "    return df\n",
    "    \n",
    "def sample_cgibbs_table(cgibbs_inputs, stan_model, advi_inputs, n_chains, n_epochs, factor_names, response_names, tepoch, titer, failed_seeds):\n",
    "\n",
    "    return pd.concat([sample_cgibbs_sequence(cgibbs_inputs, stan_model, advi_inputs, chain_ix, n_epochs, factor_names, response_names, tepoch, titer) for chain_ix in range(n_chains + len(failed_seeds)) if chain_ix not in failed_seeds])\n",
    "\n",
    "def sample_cgibbs_sequence(cgibbs_inputs, stan_model, advi_inputs, chain_ix, n_epochs, factor_names, response_names, tepoch, titer):\n",
    "\n",
    "    rng = np.random.default_rng(chain_ix)\n",
    "    advi_samples = stan_model.vb(data=advi_inputs, iter=1, init=0, seed=chain_ix)#rng.integers(0, 2147483647))\n",
    "    advi_arrays = format_advi_output(advi_samples['sampler_param_names'], advi_samples['sampler_params'])\n",
    "    init = ([[np.mean(advi_arrays['intercept'][:, :-1], 0)]] + [np.mean(advi_arrays['coefs'][:, :-1], 0).T[lo:(hi+1)] for lo, hi in zip(advi_inputs['lo'] - 1, advi_inputs['hi'] - 1)],\n",
    "            [np.linalg.inv(a) for a in np.mean(advi_arrays['cov_factor'], 0)])\n",
    "    n_samples = int(tepoch * n_epochs / titer) + 1\n",
    "    sampler = xfx.mvglm.multinomial.sample_posterior(*cgibbs_inputs, init=init, ome=rng)\n",
    "    samples = [next(sampler) for _ in  range(n_samples)]\n",
    "    rfx_samples = package_cgibbs_samples(samples, factor_names, response_names, chain_ix, 0)\n",
    "    return split_epochs(rfx_samples, n_epochs, tepoch, titer)\n",
    "\n",
    "def package_cgibbs_samples(samples, factor_names, response_names, chain_ix, epoch_ix):\n",
    "\n",
    "    rfx_samples, _ = zip(*samples)\n",
    "    rfx_samples = [np.array(samples_) for samples_ in zip(*rfx_samples)]\n",
    "    return package_rfx_samples(rfx_samples, ['_const'] + factor_names, response_names, 'cGibbs', chain_ix, epoch_ix)\n",
    "\n",
    "def split_epochs(samples, n_epochs, tepoch, titer):\n",
    "\n",
    "    n_samples = np.int64(np.arange(1, n_epochs + 1) * (tepoch / titer))\n",
    "    summ_by_epoch = [est_post_moms(samples.iloc[:, (n // 2):(n)]).reset_index() for n in n_samples]\n",
    "    for i, summ_ in enumerate(summ_by_epoch):\n",
    "        summ_['epoch'] = i\n",
    "    summ_by_epoch = pd.concat(summ_by_epoch)\n",
    "    return summ_by_epoch.set_index(summ_by_epoch.columns.drop('value').tolist()).value\n",
    "\n",
    "def package_advi_samples(samples, data, factor_names, response_names, chain_ix, epoch_ix):\n",
    "\n",
    "    alp0_samples = samples['intercept'][:, :-1]\n",
    "    alp_samples = [[alp_[:, lo:(hi+1)].T for lo, hi in zip(data['lo'] - 1, data['hi'] - 1)] for alp_ in samples['coefs'][:, :-1]]\n",
    "    rfx_samples = [np.array(samples_) for samples_ in zip(*[[alp0_[np.newaxis]] + alp_ for alp0_, alp_ in zip(alp0_samples, alp_samples)])]\n",
    "    return package_rfx_samples(rfx_samples, ['_const'] + factor_names, response_names, 'Stan/ADVI', chain_ix, epoch_ix)\n",
    "\n",
    "def sample_advi_table(model, data, n_iter, n_chains, n_epochs, factor_names, response_names):\n",
    "\n",
    "    i = 0\n",
    "    summ_coefs = []\n",
    "    failed_seeds = []\n",
    "    while len(summ_coefs) < n_chains:\n",
    "        try:\n",
    "            summ_coefs.append(sample_advi_sequence(model, data, n_iter, i, n_epochs, factor_names, response_names))\n",
    "        except RuntimeError:\n",
    "            failed_seeds.append(i)\n",
    "        i += 1\n",
    "    return pd.concat(summ_coefs), failed_seeds\n",
    "\n",
    "def sample_advi_sequence(model, data, n_iter, chain_ix, n_epochs, factor_names, response_names):\n",
    "\n",
    "    summ_coefs = [sample_advi_cell(model, data, n_iter, chain_ix, i, factor_names, response_names) for i in range(n_epochs)]\n",
    "    return pd.concat(summ_coefs)\n",
    "\n",
    "def sample_advi_cell(model, data, n_iter, chain_ix, epoch_ix, factor_names, response_names):\n",
    "\n",
    "    rng = np.random.default_rng(chain_ix)\n",
    "    samples = model.vb(data=data, iter=n_iter*(epoch_ix+1), init=0, seed=chain_ix, tol_rel_obj=1e-9)\n",
    "    arrays = format_advi_output(samples['sampler_param_names'], samples['sampler_params'])\n",
    "    rfx_samples = package_advi_samples(arrays, data, factor_names, response_names, chain_ix, epoch_ix)\n",
    "    rfx_summ = est_post_moms(rfx_samples)\n",
    "    return rfx_summ\n",
    "\n",
    "def format_advi_output(block_names, block_samples):\n",
    "\n",
    "    uq_names = list(set([s.split('[')[0] for s in block_names]))\n",
    "    indices = {un: np.int32([re.findall('\\[(.+)\\]', n)[0].split(',') if '[' in n else np.array([]) for n in block_names if un == n.split('[')[0]]) - 1 for un in uq_names}\n",
    "    samples = {un: [s for n, s in zip(block_names, block_samples) if un == n.split('[')[0]] for un in uq_names}\n",
    "    arrays = {un: np.empty(np.append(indices[un].max(0) + 1, 1000)) for un in uq_names}\n",
    "    for un in uq_names:\n",
    "        for ix, s in zip(indices[un], samples[un]):\n",
    "            arrays[un][tuple(ix)] = s\n",
    "        arrays[un] = np.transpose(arrays[un], [-1, *range(len(arrays[un].shape) - 1)])\n",
    "    return arrays"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# config\n",
    "\n",
    "factor_names = ['province_id', 'activity', 'age', 'education', 'municipality_size', 'voting_recall', 'gender']\n",
    "response_names = ['conservatives', 'social_democrats']\n",
    "exclude = ['abstention', 'invalid']\n",
    "\n",
    "n_chains = 1\n",
    "n_epochs = 10\n",
    "n_iter = 1024"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# construct inputs\n",
    "\n",
    "cis = pd.read_csv('paper/data/cis.csv')\n",
    "cis = cis.loc[(cis.study_id == '2019-11-10') & (~cis.voting_intention.isin(exclude)) & (~cis.voting_intention.isna())]\n",
    "cis['response'] = np.where(cis.voting_intention.isin(response_names), cis.voting_intention, '_others')\n",
    "cis['voting_recall'] = np.where(cis.voting_recall.isin(response_names), cis.voting_recall, '_others')\n",
    "cis = cis[factor_names + ['response']].dropna()\n",
    "codes = cis.apply(lambda x: x.astype('category').cat.codes)\n",
    "response = pd.get_dummies(codes.response)\n",
    "indices = codes.drop('response', 1)\n",
    "n_levels = np.max(indices, 0).astype(np.int64) + 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# construct advi inputs\n",
    "\n",
    "counts = codes.groupby(codes.columns.tolist()).size().unstack('response').fillna(0)\n",
    "coef_idx = counts.index.to_frame() + np.hstack([0, np.cumsum(n_levels[:-1])]) + 1\n",
    "advi_inputs = {\n",
    "    'n_strata': counts.shape[0],\n",
    "    'n_parties': counts.shape[1],\n",
    "    'n_factors': len(n_levels),\n",
    "    'n_coefs': n_levels.sum(),\n",
    "    'prior_df': counts.shape[1] - 1,\n",
    "    'lo': np.hstack([0, np.cumsum(n_levels[:-1])]) + 1,\n",
    "    'hi': np.cumsum(n_levels).values,\n",
    "    'coef_idx': coef_idx.values,\n",
    "    'counts': counts.applymap(int).values}"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# measure advi iteration time\n",
    "\n",
    "stan_model = stan.StanModel('paper/stan/xfx_mvlogit2.stan')\n",
    "t0 = datetime.datetime.now()\n",
    "stan_model.vb(data=advi_inputs, seed=0, iter=n_iter * n_epochs, tol_rel_obj=1e-9)\n",
    "t1 = datetime.datetime.now()\n",
    "tepoch = (t1 - t0).total_seconds() / n_epochs"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# wall time per advi iteration block\n",
    "\n",
    "print(tepoch)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sample advi summaries\n",
    "\n",
    "advi_summ, failed_seeds = sample_advi_table(stan_model, advi_inputs, n_iter, n_chains, n_epochs, factor_names, response_names)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# construct cgibbs inputs\n",
    "\n",
    "prior_n_tau = np.repeat(len(response_names), len(n_levels))\n",
    "cgibbs_inputs = (response.values, n_levels.values, indices.values, None, prior_n_tau)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# measure cgibbs iteration time\n",
    "\n",
    "sampler = xfx.mvglm.multinomial.sample_posterior(*cgibbs_inputs, ome=np.random.default_rng(0))\n",
    "next(sampler)\n",
    "t0 = datetime.datetime.now()\n",
    "all(next(sampler) for _ in  range(100))\n",
    "t1 = datetime.datetime.now()\n",
    "cgibbs_titer = (t1 - t0).total_seconds() / 100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sample cgibbs summaries\n",
    "\n",
    "cgibbs_summ = sample_cgibbs_table(cgibbs_inputs, stan_model, advi_inputs, n_chains, n_epochs, factor_names, response_names, tepoch, cgibbs_titer, failed_seeds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# marginal posterior summaries for advi\n",
    "\n",
    "advi_summ"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# marginal posterior summaries for cgibbs\n",
    "\n",
    "cgibbs_summ"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd048270a795beff4afac506b9f5a1bba57b2b1bd6227e7fa82f4fe31bf58cdd14a",
   "display_name": "Python 3.8.5 64-bit ('xfx_remote-OVPgIAIG': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "48270a795beff4afac506b9f5a1bba57b2b1bd6227e7fa82f4fe31bf58cdd14a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}