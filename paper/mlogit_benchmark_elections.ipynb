{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pystan as stan\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import xfx.mvglm.cmult\n",
    "import xfx.misc.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def package_gibbs_samples(samples, factor_names, response_names, meta):\n",
    "\n",
    "    rfx_samples, prec_samples = zip(*samples)\n",
    "    rfx_samples = [np.array(samples_) for samples_ in zip(*rfx_samples)]\n",
    "    prec_samples = np.trace(prec_samples, axis1=2, axis2=3).T\n",
    "    return package_rfx_samples(rfx_samples, ['_const'] + factor_names, response_names, meta), package_prec_samples(prec_samples, factor_names, meta)\n",
    "\n",
    "def package_nuts_samples(samples, data, factor_names, response_names, meta):\n",
    "\n",
    "    alp0_samples = samples['intercept'][:, 0, :-1]\n",
    "    alp_samples = [[alp_[:, lo:(hi+1)].T for lo, hi in zip(data['lo'] - 1, data['hi'] - 1)] for alp_ in samples['coefs'][:, 0, :-1]]\n",
    "    rfx_samples = [np.array(samples_) for samples_ in zip(*[[alp0_[np.newaxis]] + alp_ for alp0_, alp_ in zip(alp0_samples, alp_samples)])]\n",
    "    prec_samples = np.array([[np.trace(np.linalg.inv(tau__)) for tau__ in tau_] for tau_ in samples['cov_factor'][:, 0]]).T\n",
    "    return package_rfx_samples(rfx_samples, ['_const'] + factor_names, response_names, meta), package_prec_samples(prec_samples, factor_names, meta)\n",
    "\n",
    "def package_rfx_samples(rfx_samples, factor_names, response_names, meta):\n",
    "\n",
    "    dfs = []\n",
    "    for i, (samples_, factor_name) in enumerate(zip(rfx_samples, factor_names)):\n",
    "        for j in range(samples_.shape[1]):\n",
    "            df_ = pd.DataFrame(samples_[:, j].T, index=response_names)\n",
    "            df_.index = df_.index.rename('response')\n",
    "            df_.columns = df_.columns.rename('iter')\n",
    "            df_['factor'] = factor_name\n",
    "            df_['level'] = j\n",
    "            for k, v in meta.items():\n",
    "                df_[k] = v\n",
    "            dfs.append(df_)\n",
    "    df = pd.concat(dfs).reset_index().set_index(['factor', 'level', 'response'] + list(meta.keys()))\n",
    "    return df\n",
    "\n",
    "def package_prec_samples(prec_samples, factor_names, meta):\n",
    "\n",
    "    df = pd.DataFrame(prec_samples, index=factor_names)\n",
    "    df.index = df.index.rename('factor')\n",
    "    df.columns = df.columns.rename('iter')\n",
    "    for k, v in meta.items():\n",
    "        df[k] = v\n",
    "    df = df.reset_index().set_index(['factor'] + list(meta.keys()))\n",
    "    return df\n",
    "\n",
    "def est_acf(samples, n_lags):\n",
    "\n",
    "    acf = samples.apply(lambda x: xfx.misc.plot.est_acf(x.values, n_lags), 1, False, 'expand')\n",
    "    acf.columns = acf.columns.rename('lag')\n",
    "    return acf\n",
    "\n",
    "def est_ess(acfs, titer):\n",
    "    \n",
    "    df = pd.DataFrame(index=acfs.index)\n",
    "    df['iat[iter]'] = acfs.apply(lambda x: xfx.misc.plot.est_int_autocor(x.values), 1, False, 'expand').rename('iat')\n",
    "    df['iat[sec]'] = df['iat[iter]'] * titer\n",
    "    df['rate[iter]'] = 1 / (2 * df['iat[iter]'])\n",
    "    df['rate[sec]'] = df['rate[iter]'] / titer\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "factor_names = ['province_id', 'activity', 'age', 'education', 'municipality_size', 'voting_recall', 'gender']\n",
    "response_names = ['conservatives', 'social_democrats']\n",
    "exclude = ['abstention', 'invalid']\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# construct common inputs\n",
    "\n",
    "cis = pd.read_csv('paper/data/cis.csv')\n",
    "cis = cis.loc[(cis.study_id == '2019-11-10') & (~cis.voting_intention.isin(exclude)) & (~cis.voting_intention.isna())]\n",
    "cis['response'] = np.where(cis.voting_intention.isin(response_names), cis.voting_intention, '_others')\n",
    "cis['voting_recall'] = np.where(cis.voting_recall.isin(response_names), cis.voting_recall, '_others')\n",
    "cis = cis[factor_names + ['response']].dropna()\n",
    "codes = cis.apply(lambda x: x.astype('category').cat.codes)\n",
    "response = pd.get_dummies(codes.response)\n",
    "indices = codes.drop('response', 1)\n",
    "n_levels = np.max(indices, 0).astype(np.int64) + 1\n",
    "rng = np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# construct nuts inputs\n",
    "\n",
    "counts = codes.groupby(codes.columns.tolist()).size().unstack('response').fillna(0)\n",
    "coef_idx = counts.index.to_frame() + np.hstack([0, np.cumsum(n_levels[:-1])]) + 1\n",
    "nuts_inputs = {\n",
    "    'n_strata': counts.shape[0],\n",
    "    'n_parties': counts.shape[1],\n",
    "    'n_factors': len(n_levels),\n",
    "    'n_coefs': n_levels.sum(),\n",
    "    'prior_df': counts.shape[1] - 1,\n",
    "    'lo': np.hstack([0, np.cumsum(n_levels[:-1])]) + 1,\n",
    "    'hi': np.cumsum(n_levels).values,\n",
    "    'coef_idx': coef_idx.values,\n",
    "    'counts': counts.applymap(int).values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample stan\n",
    "\n",
    "nuts_n_samples = 1000\n",
    "stan_model = stan.StanModel('paper/stan/xfx_mvlogit2.stan')\n",
    "t0 = datetime.datetime.now()\n",
    "nuts_sampler = stan_model.sampling(data=nuts_inputs, iter=2*nuts_n_samples, warmup=nuts_n_samples, chains=1, seed=0)\n",
    "t1 = datetime.datetime.now()\n",
    "nuts_titer = (t1 - t0).total_seconds() / nuts_n_samples\n",
    "nuts_leaps = nuts_sampler.get_sampler_params(inc_warmup=False)[0]['n_leapfrog__'].mean()\n",
    "nuts_samples = nuts_sampler.extract(['intercept', 'coefs', 'cov_factor'], permuted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute nuts summaries\n",
    "\n",
    "nuts_rfx_samples, nuts_prec_samples = package_nuts_samples(nuts_samples, nuts_inputs, factor_names, response_names, {'algo': 'NUTS'})\n",
    "nuts_rfx_acf, nuts_prec_acf = (est_acf(samples_, 64) for samples_ in (nuts_rfx_samples, nuts_prec_samples))\n",
    "nuts_rfx_ess, nuts_prec_ess = (est_ess(acfs_, nuts_titer) for acfs_ in (nuts_rfx_acf, nuts_prec_acf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# construct gibbs inputs\n",
    "\n",
    "prior_n_tau = np.repeat(len(response_names), len(n_levels))\n",
    "gibbs_inputs = (response.values, n_levels.values, indices.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sample lc\n",
    "\n",
    "lc_n_samples = 10000\n",
    "lc_sampler = xfx.mvglm.cmult.sample_posterior(*gibbs_inputs, ome=rng)\n",
    "next(lc_sampler)\n",
    "t0 = datetime.datetime.now()\n",
    "lc_samples = [next(lc_sampler) for _ in range(2 * lc_n_samples)][lc_n_samples:]\n",
    "t1 = datetime.datetime.now()\n",
    "lc_titer = (t1 - t0).total_seconds() / lc_n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample vanilla\n",
    "\n",
    "van_n_samples = 10000\n",
    "van_sampler = xfx.mvglm.cmult.sample_posterior(*gibbs_inputs, ome=rng, collapse=False)\n",
    "next(lc_sampler)\n",
    "t0 = datetime.datetime.now()\n",
    "van_samples = [next(van_sampler) for _ in range(2 * van_n_samples)][van_n_samples:]\n",
    "t1 = datetime.datetime.now()\n",
    "van_titer = (t1 - t0).total_seconds() / van_n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute lc summaries\n",
    "\n",
    "lc_rfx_samples, lc_prec_samples = package_gibbs_samples(lc_samples, factor_names, response_names, {'algo': 'const/LC'})\n",
    "lc_rfx_acf, lc_prec_acf = (est_acf(samples_, 256) for samples_ in (lc_rfx_samples, lc_prec_samples))\n",
    "lc_rfx_ess, lc_prec_ess = (est_ess(acfs_, lc_titer) for acfs_ in (lc_rfx_acf, lc_prec_acf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute vanilla summaries\n",
    "\n",
    "van_rfx_samples, van_prec_samples = package_gibbs_samples(van_samples, factor_names, response_names, {'algo': 'const/vGS'})\n",
    "van_rfx_acf, van_prec_acf = (est_acf(samples_, 256) for samples_ in (van_rfx_samples, van_prec_samples))\n",
    "van_rfx_ess, van_prec_ess = (est_ess(acfs_, van_titer) for acfs_ in (van_rfx_acf, van_prec_acf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack\n",
    "\n",
    "rfx_acf = pd.concat([lc_rfx_acf, van_rfx_acf, nuts_rfx_acf])\n",
    "prec_acf = pd.concat([lc_prec_acf, van_prec_acf, nuts_prec_acf])\n",
    "rfx_ess = pd.concat([lc_rfx_ess, van_rfx_ess, nuts_rfx_ess])\n",
    "prec_ess = pd.concat([lc_prec_ess, van_prec_ess, nuts_prec_ess])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf = pd.concat([rfx_acf, prec_acf]).reset_index().melt(id_vars=['algo', 'factor', 'level', 'response'], var_name='lag')\n",
    "acf['level'] = acf.level.fillna(0)\n",
    "acf['factor'] = acf.factor.astype('category').cat.codes\n",
    "acf['group'] = (acf.factor.astype('str') + '-' + acf.level.astype('str')).astype('category').cat.codes\n",
    "acf['time'] = acf.lag.astype(int) * np.select([acf.algo == 'const/LC-MwG', acf.algo == 'const/Van-MwG'], [lc_titer, van_titer], nuts_titer)\n",
    "ess = pd.concat([rfx_ess, prec_ess]).reset_index()\n",
    "ess['level'] = ess.level.fillna(0)\n",
    "\n",
    "f, axes = plt.subplots(1, 2, figsize=(2 * (8/5 + 4/3), 2), gridspec_kw={'width_ratios': [8/5, 4/3]})\n",
    "g = sns.lineplot(data=acf, x='time', y='value', hue='algo', style='group', dashes=False, markers=False, legend=False, ci=None, alpha=1/3, lw=1/3, ax=axes[0], hue_order=('const/LC-MwG', 'NUTS', 'const/Van-MwG'))\n",
    "g.set(xlabel='wall time [sec]', ylabel='ACF', xlim=(-1, 21))\n",
    "g = sns.boxplot(data=ess, y='algo', x='rate[sec]', order=('const/LC-MwG', 'NUTS', 'const/Van-MwG'), linewidth=1, fliersize=1, sym='o', ax=axes[1])\n",
    "g.set(ylabel='$\\\\quad$', xlabel='ESS/sec', xscale='log')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xfx-v8IVivw0-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "metadata": {
   "interpreter": {
    "hash": "48270a795beff4afac506b9f5a1bba57b2b1bd6227e7fa82f4fe31bf58cdd14a"
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "bfa90eb105e02586f49d13927d95a3f8b2865db9e646a82fa6bd5f993c25bf8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
