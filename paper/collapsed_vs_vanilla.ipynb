{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# dependencies\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.special import expit\n",
    "from xfx.glm.gaussian import sample_posterior as sample_gaussian\n",
    "from xfx.glm.binomial import sample_posterior as sample_binomial\n",
    "from tests.test_glm import sample_mar_fixture\n",
    "from xfx.misc import plot\n",
    "\n",
    "sns.set()"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# spaghetti\n",
    "\n",
    "def sample_iat(n_levels_, n_samples, n_warmup, n_acf_lags, ome):\n",
    "\n",
    "    run = ome.__getstate__()['state']['state']\n",
    "    fixture = sample_mar_fixture(np.repeat(n_levels_, 2), 1e100, 1e-100, 0.9, ome)[0]\n",
    "    gauss_fixture = (ome.normal(fixture[0], 1), None, np.ones_like(fixture[0]), np.repeat(n_levels_, 2), fixture[1])\n",
    "    binom_fixture = (np.float64(expit(fixture[0]) < ome.uniform(size=len(fixture[0]))), np.ones_like(fixture[0]), np.repeat(n_levels_, 2), fixture[1])\n",
    "\n",
    "    gauss_collapsed_sampler, gauss_vanilla_sampler = (\n",
    "        sample_gaussian(*gauss_fixture, np.ones(2), np.ones(2), np.inf, 1, None, b, ome) for b in (True, False))\n",
    "    binom_collapsed_sampler, binom_vanilla_sampler = (\n",
    "        sample_binomial(*binom_fixture, np.ones(2), np.ones(2), None, b, ome) for b in (True, False))\n",
    "    gauss_collapsed_samples, gauss_vanilla_samples, binom_collapsed_samples, binom_vanilla_samples = (\n",
    "        [next(sampler)[:2] for _ in range(n_samples + n_warmup)][n_warmup:] for sampler in (\n",
    "            gauss_collapsed_sampler, gauss_vanilla_sampler, binom_collapsed_sampler, binom_vanilla_sampler))\n",
    "\n",
    "    gauss_collapsed_df, gauss_vanilla_df, binom_collapsed_df, binom_vanilla_df = (\n",
    "        package_samples(samples, mod, algo, len(gauss_fixture[0]), run) for mod, algo, samples in (\n",
    "            ('linear', 'collapsed', gauss_collapsed_samples), ('linear', 'vanilla', gauss_vanilla_samples), ('logistic', 'collapsed', binom_collapsed_samples), ('logistic', 'vanilla', binom_vanilla_samples)))\n",
    "    df = pd.concat([gauss_collapsed_df, gauss_vanilla_df, binom_collapsed_df, binom_vanilla_df])\n",
    "\n",
    "    return est_iat(df, n_acf_lags)\n",
    "\n",
    "def package_samples(samples, model, algo, n_obs, run):\n",
    "\n",
    "    bet, tau = zip(*samples)\n",
    "    alp0 = np.array([bet_[0][0] for bet_ in bet])\n",
    "    alp = np.array([bet_[1:] for bet_ in bet])\n",
    "    mean = np.mean(alp, 2).T\n",
    "    prior_prec = np.array(tau).T\n",
    "    dfs = [pd.DataFrame({'iter': np.arange(len(samples)), 'value': np.array(alp0), 'factor': [0] * len(samples), 'stat': ['mean'] * len(samples)})]\n",
    "    for i in range(mean.shape[0]):\n",
    "        df_mean_ = pd.DataFrame({'iter': np.arange(len(samples)), 'value': mean[i], 'factor': [i + 1] * len(samples), 'stat': ['mean'] * len(samples)})\n",
    "        df_prior_prec_ = pd.DataFrame({'iter': np.arange(len(samples)), 'value': prior_prec[i], 'factor': [i + 1] * len(samples), 'stat': ['prior_prec'] * len(samples)})\n",
    "        dfs.extend([df_mean_, df_prior_prec_])\n",
    "    df = pd.concat(dfs)\n",
    "    df['model'] = model\n",
    "    df['algo'] = algo\n",
    "    df['n_obs'] = n_obs\n",
    "    df['run'] = run\n",
    "    return df.set_index(['model', 'algo', 'n_obs', 'run', 'factor', 'stat', 'iter']).unstack('iter').value\n",
    "\n",
    "def est_acf(samples, n_lags):\n",
    "\n",
    "    acf = samples.apply(lambda x: plot.est_acf(x.values, n_lags), 1, False, 'expand')\n",
    "    acf.columns = acf.columns.rename('lag')\n",
    "    return acf\n",
    "\n",
    "def est_iat(samples, n_acf_lags):\n",
    "    \n",
    "    acf = est_acf(samples, n_acf_lags)\n",
    "    iat = acf.apply(lambda x: plot.est_int_autocor(x.values), 1, False, 'expand').rename('iat')\n",
    "    return iat"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# config\n",
    "\n",
    "seed = 0\n",
    "n_runs = 10\n",
    "n_levels = 2 ** np.arange(5, 11)\n",
    "n_samples = 1000#0\n",
    "n_warmup = 10\n",
    "n_acf_lags = 128\n",
    "\n",
    "ome = np.random.default_rng(seed)"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# run\n",
    "\n",
    "df = pd.concat([pd.concat([sample_iat(n_levels_, n_samples, n_warmup, n_acf_lags, ome) for n_levels_ in n_levels]) for _ in range(n_runs)])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "update_intercept() missing 1 required positional argument: 'ome'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fbd46327f6ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_iat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_levels_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_warmup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_acf_lags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mome\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn_levels_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mn_levels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-fbd46327f6ec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_iat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_levels_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_warmup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_acf_lags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mome\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn_levels_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mn_levels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-fbd46327f6ec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_iat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_levels_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_warmup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_acf_lags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mome\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn_levels_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mn_levels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-38c3c504c347>\u001b[0m in \u001b[0;36msample_iat\u001b[0;34m(n_levels_, n_samples, n_warmup, n_acf_lags, ome)\u001b[0m\n\u001b[1;32m     12\u001b[0m     binom_collapsed_sampler, binom_vanilla_sampler = (\n\u001b[1;32m     13\u001b[0m         sample_binomial(*binom_fixture, np.ones(2), np.ones(2), None, b, ome) for b in (True, False))\n\u001b[0;32m---> 14\u001b[0;31m     gauss_collapsed_samples, gauss_vanilla_samples, binom_collapsed_samples, binom_vanilla_samples = (\n\u001b[0m\u001b[1;32m     15\u001b[0m         [next(sampler)[:2] for _ in range(n_samples + n_warmup)][n_warmup:] for sampler in (\n\u001b[1;32m     16\u001b[0m             gauss_collapsed_sampler, gauss_vanilla_sampler, binom_collapsed_sampler, binom_vanilla_sampler))\n",
      "\u001b[0;32m<ipython-input-2-38c3c504c347>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m         sample_binomial(*binom_fixture, np.ones(2), np.ones(2), None, b, ome) for b in (True, False))\n\u001b[1;32m     14\u001b[0m     gauss_collapsed_samples, gauss_vanilla_samples, binom_collapsed_samples, binom_vanilla_samples = (\n\u001b[0;32m---> 15\u001b[0;31m         [next(sampler)[:2] for _ in range(n_samples + n_warmup)][n_warmup:] for sampler in (\n\u001b[0m\u001b[1;32m     16\u001b[0m             gauss_collapsed_sampler, gauss_vanilla_sampler, binom_collapsed_sampler, binom_vanilla_sampler))\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-38c3c504c347>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m         sample_binomial(*binom_fixture, np.ones(2), np.ones(2), None, b, ome) for b in (True, False))\n\u001b[1;32m     14\u001b[0m     gauss_collapsed_samples, gauss_vanilla_samples, binom_collapsed_samples, binom_vanilla_samples = (\n\u001b[0;32m---> 15\u001b[0;31m         [next(sampler)[:2] for _ in range(n_samples + n_warmup)][n_warmup:] for sampler in (\n\u001b[0m\u001b[1;32m     16\u001b[0m             gauss_collapsed_sampler, gauss_vanilla_sampler, binom_collapsed_sampler, binom_vanilla_sampler))\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/research/hierarch/xfx_remote/xfx/glm/gibbs.py\u001b[0m in \u001b[0;36msample_disp_posterior\u001b[0;34m(y1, y2, n, j, i, eval_part, eval_base, prior_n_tau, prior_est_tau, prior_n_phi, prior_est_phi, init, collapse, ome)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0malp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_coefs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_ord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollapse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_part\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior_n_tau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muv_conjugate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_factor_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_n_tau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_est_tau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/research/hierarch/xfx_remote/xfx/glm/gibbs.py\u001b[0m in \u001b[0;36mupdate_coefs\u001b[0;34m(y1, n, i, i_ord, alp0, alp, tau, phi, collapse, eval_part, samplers, ome)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mnew_alp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_alp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtau_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         new_alp0, new_alp[k_] = update_single_coef(y1, n, i, i_ord, k_, new_alp0, new_alp, tau_,\n\u001b[0m\u001b[1;32m     67\u001b[0m                                                    phi, collapse, eval_part, sampler_, ome)\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_alp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_alp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/research/hierarch/xfx_remote/xfx/glm/gibbs.py\u001b[0m in \u001b[0;36mupdate_single_coef\u001b[0;34m(y1, n, i, i_ord, k_, alp0, alp, tau_, phi, collapse, eval_part, sampler, ome)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mnew_alp_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_bet_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malp0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mnew_alp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_intercept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_alp_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_part\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_alp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_alp_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: update_intercept() missing 1 required positional argument: 'ome'"
     ]
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# dump\n",
    "\n",
    "df.to_csv('paper/output/collapsed_vs_vanilla_ess.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# configure for export\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('pgf')\n",
    "matplotlib.rcParams.update({\n",
    "    'pgf.texsystem': 'xelatex',\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': False,\n",
    "    'pgf.rcfonts': False,\n",
    "    'axes.labelsize': 10,\n",
    "    'axes.titlesize': 10,\n",
    "    'font.size': 10\n",
    "})\n",
    "df = pd.read_csv('paper/output/collapsed_vs_vanilla_ess.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# item 1\n",
    "\n",
    "df = df.groupby(['model', 'algo', 'n_obs', 'factor', 'stat']).iat.mean().reset_index()\n",
    "df['iat'] *= 2\n",
    "df['group'] = df.factor.astype(str) + '-' + df.stat\n",
    "g = sns.relplot(data=df, x='n_obs', y='iat', hue='algo', row='model', col='factor', style='stat', kind='line', aspect=4/3, height=1.25, markers=False, legend=False, lw=1, facet_kws={'margin_titles':True})\n",
    "xticks, yticks = 10 ** np.arange(2, 6), 10 ** np.arange(3)\n",
    "g.set_titles(row_template='{row_name}', col_template='factor {col_name}')\n",
    "g.set(xscale='log', yscale='log')\n",
    "g.set(xticks=xticks, yticks=yticks)\n",
    "g.axes[0,0].set(ylabel='IAT')\n",
    "g.axes[1,0].set(xlabel=None, ylabel='IAT')\n",
    "g.axes[1,1].set(xlabel='number of observations')\n",
    "g.axes[1,2].set(xlabel=None)\n",
    "g.fig.subplots_adjust(wspace=.1, hspace=.16)\n",
    "\n",
    "plt.savefig('paper/plots/collapsed_vs_vanilla_ess.pdf', bbox_inches='tight')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('xfx_remote-OVPgIAIG': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "48270a795beff4afac506b9f5a1bba57b2b1bd6227e7fa82f4fe31bf58cdd14a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}